---
title: "limma"
output: html_document
date: "2023-09-05"
editor_options: 
  chunk_output_type: console
---

Loading Libraries
```{r warning=FALSE, message=FALSE}
suppressPackageStartupMessages({
  library(tidyverse)
  library(GenomicFeatures)
  library(rtracklayer)
  library(dplyr)
  library(Rsamtools)
  library(glmnet)
  library(ggpubr)
  library(DESeq2)
  library(apeglm)
  library(limma)
})
```

Without nanocount
```{r warning=FALSE, message=FALSE}
hdeg_rep1 <- read.csv("/home/bhavika/Desktop/Nanograd/Data_2/Undeg_Hdeg_before_filtering/hdeg_rep1.csv")
udeg_rep1 <- read.csv("/home/bhavika/Desktop/Nanograd/Data_2/Undeg_Hdeg_before_filtering/udeg_rep1.csv")

udeg_rep2 <- read.csv("/home/bhavika/Desktop/Nanograd/Data_2/Undeg_Hdeg_before_filtering/udeg_rep2.csv")
hdeg_rep2 <- read.csv("/home/bhavika/Desktop/Nanograd/Data_2/Undeg_Hdeg_before_filtering/hdeg_rep2.csv")
```

With nanocount Data
```{r warning=FALSE, message=FALSE}
udeg_rep1 <- read.csv("/home/bhavika/Desktop/Nanograd/Data_2/nanocount_output_bh/udeg_rep1_nano.csv")
hdeg_rep1 <- read.csv("/home/bhavika/Desktop/Nanograd/Data_2/nanocount_output_bh/hdeg_rep1_nano.csv")

udeg_rep2 <- read.csv("/home/bhavika/Desktop/Nanograd/Data_2/nanocount_output_bh/udeg_rep2_nano.csv")
hdeg_rep2 <- read.csv("/home/bhavika/Desktop/Nanograd/Data_2/nanocount_output_bh/hdeg_rep2_nano.csv")
```

Without nanocount + filtering (indels + 3' end)
```{r warning=FALSE, message=FALSE}
udeg_rep1 <- read.csv("/home/bhavika/Desktop/Nanograd/Data_2/Undeg_Hdeg_all_filtering/udeg_rep1_all_filtering.csv")
hdeg_rep1 <- read.csv("/home/bhavika/Desktop/Nanograd/Data_2/Undeg_Hdeg_all_filtering/hdeg_rep1_all_filtering.csv")

udeg_rep2 <- read.csv("/home/bhavika/Desktop/Nanograd/Data_2/Undeg_Hdeg_all_filtering/udeg_rep2_all_filtering.csv")
hdeg_rep2 <- read.csv("/home/bhavika/Desktop/Nanograd/Data_2/Undeg_Hdeg_all_filtering/hdeg_rep2_all_filtering.csv")
```

adding the name of the condition column in all the datasets
```{r warning=FALSE, message=FALSE}
udeg_rep1$condition <- "undegraded_1"
hdeg_rep1$condition <- "heavy_degraded_1"
udeg_rep2$condition <- "undegraded_2"
hdeg_rep2$condition <- "heavy_degraded_2"
```

selecting the required columns
```{r warning=FALSE, message=FALSE}
udeg_1 <- udeg_rep1 %>% 
  dplyr::select(Transcript, condition)
hdeg_1 <- hdeg_rep1 %>% 
  dplyr::select(Transcript, condition)
udeg_2 <- udeg_rep2 %>% 
  dplyr::select(Transcript, condition)
hdeg_2 <- hdeg_rep2 %>% 
  dplyr::select(Transcript, condition)
```

Grouping the data by transcripts and then find the number of reads of each transcript and reading the column condition as to calculate number of reads using summarise command
```{r warning=FALSE, message=FALSE}
ugrp1 <- udeg_1 %>% 
  dplyr::group_by(Transcript) %>% 
  summarise(nreads=n())
ugrp1$condition <- "undegraded_1"

hgrp1 <- hdeg_1 %>% 
  dplyr::group_by(Transcript) %>% 
  summarise(nreads=n())
hgrp1$condition <- "heavy_degraded_1"

ugrp2 <- udeg_2 %>% 
  dplyr::group_by(Transcript) %>% 
  summarise(nreads=n())
ugrp2$condition <- "undegraded_2"

hgrp2 <- hdeg_2 %>% 
  dplyr::group_by(Transcript) %>% 
  summarise(nreads=n())
hgrp2$condition <- "heavy_degraded_2"
```

Merging the data to get one dataset for all the number of reads of each transcript in each condition
```{r warning=FALSE, message=FALSE}
deg_1 <- merge(x=ugrp1, y=hgrp1, all=T)
deg_2 <- merge(x=ugrp2, y=hgrp2, all=T)

data_hu <- merge(x=deg_1, y=deg_2, all=T)
```

Converting NA's to zero
```{r warning=FALSE, message=FALSE}
data_hu[is.na(data_hu)]=0
```

Formatting the data as required by deseq2 and converting NA's to zero
```{r warning=FALSE, message=FALSE}
data <- pivot_wider(data_hu, names_from = condition, values_from = nreads)
data[is.na(data)] <- 0
```

Constructing a deseq dataset object by converting it into matrix and converting the number of reads into integer
```{r warning=FALSE, message=FALSE}
countData <- as.matrix(data[ ,-1])
colnames(countData)=c("hdeg2", "hdeg1", "undeg2", "undeg1")
rownames(countData)=data$Transcript
```

making a DGE object
```{r warning=FALSE, message=FALSE}
group <- c("degraded","degraded","control", "control")
x <- DGEList(counts=countData,group=factor(group))
```

Keeping the transcripts that have greater than 5 reads in at least 2 conditions
```{r warning=FALSE, message=FALSE}
dim(x)
x.full <- x
head(x.full$counts)
apply(x.full$counts, 2, sum)

keep <- rowSums(x.full$counts > 5) >= 2
x.full <- x.full[keep,]
dim(x.full)
```

Converting to counts per million 
```{r warning=FALSE, message=FALSE}
cpm_data <- cpm(x.full)
```

Normalising the counts
```{r warning=FALSE, message=FALSE}
x.full <- calcNormFactors(x.full)
```

Similar to PCA plot to check similarity between replicates of samples
```{r warning=FALSE, message=FALSE}
plotMDS(x.full)
```

Voom transformation and calculation of variance weights
```{r warning=FALSE, message=FALSE}
mm <- model.matrix(~0 + group) # this specifies a model where each coefficient corresponds to a group mean

y <- voom(x.full, mm, plot=T)
```

Fitting linear models
```{r warning=FALSE, message=FALSE}
fit <- lmFit(y, mm)
head(coef(fit))

contr <- makeContrasts(groupcontrol - groupdegraded, levels = colnames(coef(fit)))
contr

#estimating contrast for each gene
tmp <- contrasts.fit(fit, contr)
tmp <- eBayes(tmp)
plotSA(tmp, main="Final Model: Mean-variance Trend")

summary(decideTests(tmp))

top.table <- topTable(tmp, sort.by = "P", n=Inf)
head(top.table)
```

dets- up and down regulated transcripts
```{r warning=FALSE, message=FALSE}
a_up <- top.table %>% 
  filter(adj.P.Val < 0.05 & logFC > 1)

a_down <- top.table %>% 
  filter(adj.P.Val < 0.05 & logFC < -1)
```

adding transcript as column
```{r warning=FALSE, message=FALSE}
a_up <- tibble::rownames_to_column(a_up, "Transcript")
a_down <- tibble::rownames_to_column(a_down, "Transcript")

det <- merge(x=a_up, y=a_down, all=T)
```

merging up and down regulated dets to transcript len dataset
```{r warning=FALSE, message=FALSE}
det_m <- merge(x=udeg_rep1_txlen, y=det, by="Transcript")

up_merge_u <- merge(x=udeg_rep1_txlen, y=a_up, by="Transcript")
down_merge_u <- merge(x=udeg_rep1_txlen, y=a_down, by="Transcript")

up_merge_h <- merge(x=hdeg_rep1, y=a_up, by="Transcript")
down_merge_h <- merge(x=hdeg_rep1, y=a_down, by="Transcript")
```

distribution plot of transcript length
```{r warning=FALSE, message=FALSE}
ggplot(up_merge, aes(x=Transcript_len)) + geom_histogram(binwidth = 1, col="blue") + ggtitle("Upregulated transcripts- TL distribution- undeg rep 1") + theme_bw()+ theme(axis.text=element_text(size=12), axis.title=element_text(size=14))

ggplot(down_merge, aes(x=Transcript_len)) + geom_histogram(binwidth = 1, col="blue") + ggtitle("Down regulated transcripts- TL distribution- undeg rep 1") + theme_bw()+ theme(axis.text=element_text(size=12), axis.title=element_text(size=14)) 

ggplot(det_m, aes(x=Transcript_len)) + geom_histogram(binwidth = 1, col="blue") + ggtitle("DETs-TL distribution") + theme_bw() + labs(x="Transcript length", y="count") + theme(axis.text=element_text(size=16), axis.title=element_text(size=18)) + theme(plot.title = element_text(size=18, face = "bold"))
```

merging dataset to get read lengths
```{r warning=FALSE, message=FALSE}
merge_u <- merge(x=udeg_rep1, y=det, by="Transcript")
merge_h <- merge(x=hdeg_rep1, y=det, by="Transcript")
```

read length distribution plot
```{r warning=FALSE, message=FALSE}
ggplot(merge_u, aes(x=new_ReadLen)) + geom_histogram(binwidth = 1, col="blue") + ggtitle("DETs-Distribution of Read lengths-non-degraded") + theme_bw() + labs(x="Read Length", y="Number of Reads") + theme(axis.text=element_text(size=16), axis.title=element_text(size=18)) + theme(plot.title = element_text(size=18, face = "bold")) + xlim(0,3000)

ggplot(merge_h, aes(x=new_ReadLen)) + geom_histogram(binwidth = 1, col="blue") + ggtitle("DETs-Distribution of Read lengths-heavily degraded") + theme_bw() + labs(x="Read Length", y="Number of Reads") + theme(axis.text=element_text(size=16), axis.title=element_text(size=18)) + theme(plot.title = element_text(size=18, face = "bold"))+ xlim(0,3000)
```

comparing edgeR and limma-voom transcripts in the results of after filtration
```{r warning=FALSE, message=FALSE}
merge1 <- merge(x=z_det, y=det, by="Transcript")
f <- merge(x=a_down, y=z_up, by="Transcript")
c <- e_down %>% 
  filter(Transcript=="ENST00000389680.2")
```

